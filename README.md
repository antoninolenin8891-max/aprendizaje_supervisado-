ğŸ“ Dashboard Interactivo - Aprendizaje Supervisado
ğŸ“‹ DescripciÃ³n del Proyecto
Dashboard interactivo desarrollado en Python que integra y documenta todos los algoritmos de aprendizaje supervisado abordados durante la Unidad I. Este proyecto demuestra la implementaciÃ³n prÃ¡ctica de modelos de machine learning utilizando ProgramaciÃ³n Orientada a Objetos y una interfaz amigable construida con Streamlit.

ğŸš€ CaracterÃ­sticas Principales
ğŸ¤– Algoritmos Implementados
ğŸ“ˆ RegresiÃ³n Lineal - PredicciÃ³n de valores continuos

ğŸ¯ RegresiÃ³n Ridge y Lasso - RegularizaciÃ³n para mejorar generalizaciÃ³n

ğŸ“Š RegresiÃ³n LogÃ­stica - ClasificaciÃ³n binaria y multiclase

ğŸ‘¥ K-Nearest Neighbors (KNN) - ClasificaciÃ³n y regresiÃ³n basada en instancias

ğŸŒ³ Ãrboles de DecisiÃ³n - Modelos interpretables para clasificaciÃ³n y regresiÃ³n

ğŸ§  Redes Neuronales - PerceptrÃ³n multicapa para problemas complejos

ğŸ¡ Proyecto Principal: PredicciÃ³n de Precios de Casas
Dataset: King County (mÃ¡s de 21,000 propiedades)

CaracterÃ­sticas: 21 variables predictoras (numÃ©ricas y categÃ³ricas)

Objetivo: Predecir el precio de venta de propiedades

Pipeline completo: Desde carga de datos hasta deployment

ğŸ› ï¸ TecnologÃ­as Utilizadas
Backend
Python 3.8+

scikit-learn - Algoritmos de machine learning

pandas - ManipulaciÃ³n de datos

numpy - CÃ¡lculos numÃ©ricos

matplotlib/seaborn - Visualizaciones

Frontend
Streamlit - Dashboard interactivo

Plotly - GrÃ¡ficos interactivos

Arquitectura
ProgramaciÃ³n Orientada a Objetos (POO)

PatrÃ³n MVC (Modelo-Vista-Controlador)

Pipeline modular de machine learning

ğŸ“ Estructura del Proyecto
text
ml-dashboard/
â”œâ”€â”€ main_dashboard.py          # AplicaciÃ³n principal Streamlit
â”œâ”€â”€ requirements.txt           # Dependencias del proyecto
â”œâ”€â”€ README.md                  # Este archivo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ king_county.csv       # Dataset principal
â””â”€â”€ scripts/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data_loader.py        # Clase DataLoader
    â”œâ”€â”€ data_preprocessor.py  # Clase DataPreprocessor
    â”œâ”€â”€ feature_engineer.py   # Clase FeatureEngineer
    â”œâ”€â”€ model_trainer.py      # Clase ModelTrainer
    â”œâ”€â”€ model_evaluator.py    # Clase ModelEvaluator
    â””â”€â”€ predictor.py          # Clase Predictor
ğŸ—ï¸ Arquitectura POO
Clases Principales
DataLoader
Responsabilidad: Carga y gestiÃ³n de datasets

MÃ©todos principales: load_data(), split_data()

DataPreprocessor
Responsabilidad: Limpieza y transformaciÃ³n de datos

MÃ©todos: handle_missing_values(), encode_categorical(), scale_features()

FeatureEngineer
Responsabilidad: CreaciÃ³n y selecciÃ³n de caracterÃ­sticas

MÃ©todos: create_new_features(), select_features()

ModelTrainer
Responsabilidad: Entrenamiento y ajuste de modelos

MÃ©todos: train(), cross_validate(), hyperparameter_tuning()

ModelEvaluator
Responsabilidad: EvaluaciÃ³n y mÃ©tricas de modelos

MÃ©todos: evaluate(), plot_results(), confusion_matrix()

Predictor
Responsabilidad: Realizar predicciones en nuevos datos

MÃ©todos: predict(), predict_proba()

ğŸ“Š MÃ©tricas de EvaluaciÃ³n
Para RegresiÃ³n
MSE (Mean Squared Error)

RMSE (Root Mean Squared Error)

MAE (Mean Absolute Error)

RÂ² (Coefficient of Determination)

MAPE (Mean Absolute Percentage Error)

Para ClasificaciÃ³n
Accuracy (Exactitud)

Precision (PrecisiÃ³n)

Recall (Sensibilidad)

F1-Score (Media armÃ³nica)

ROC-AUC (Curva ROC)

Matriz de ConfusiÃ³n

ğŸš€ InstalaciÃ³n y Uso
1. Clonar el repositorio
bash
git clone https://github.com/tu-usuario/ml-dashboard.git
cd ml-dashboard
2. Crear entorno virtual (recomendado)
bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
3. Instalar dependencias
bash
pip install -r requirements.txt
4. Ejecutar la aplicaciÃ³n
bash
streamlit run main_dashboard.py
5. Acceder al dashboard
Abrir http://localhost:8501 en el navegador

ğŸ“ Requisitos del Sistema
Python 3.8 o superior

4GB RAM mÃ­nimo

500MB espacio en disco

Navegador web moderno

ğŸ§ª Casos de Uso
ğŸ”§ Para Estudiantes
Aprender algoritmos de ML de manera interactiva

Probar diferentes configuraciones de hiperparÃ¡metros

Visualizar el impacto del preprocesamiento

ğŸ”¬ Para Desarrolladores
Base de cÃ³digo modular y extensible

ImplementaciÃ³n de mejores prÃ¡cticas POO

Ejemplos de pipeline completo de ML

ğŸ“š Para Educadores
Material didÃ¡ctico interactivo

Ejemplos prÃ¡cticos con datos reales

Visualizaciones explicativas

ğŸ¯ Contextos de AplicaciÃ³n por Algoritmo
RegresiÃ³n Lineal
AplicaciÃ³n: PredicciÃ³n de precios, ventas, demanda

CuÃ¡ndo usar: Relaciones lineales, interpretabilidad importante

Ventajas: Simple, interpretable, rÃ¡pido

RegresiÃ³n LogÃ­stica
AplicaciÃ³n: ClasificaciÃ³n binaria (spam, fraude, diagnÃ³stico)

CuÃ¡ndo usar: Probabilidades de clase, decisiones binarias

Ventajas: ProbabilÃ­stico, interpretable

K-Nearest Neighbors
AplicaciÃ³n: Reconocimiento de patrones, sistemas de recomendaciÃ³n

CuÃ¡ndo usar: Datos con estructura local, pocas caracterÃ­sticas

Ventajas: No paramÃ©trico, simple de implementar

Ãrboles de DecisiÃ³n
AplicaciÃ³n: ClasificaciÃ³n mÃ©dica, anÃ¡lisis de riesgo

CuÃ¡ndo usar: Interpretabilidad crucial, datos heterogÃ©neos

Ventajas: Muy interpretable, maneja mixed data types

Redes Neuronales
AplicaciÃ³n: ImÃ¡genes, texto, series temporales complejas

CuÃ¡ndo usar: Patrones no lineales, grandes volÃºmenes de datos

Ventajas: Alta capacidad de modelado, features automÃ¡ticas

ğŸ” ValidaciÃ³n de Modelos
TÃ©cnicas Implementadas
Train/Validation/Test Split - DivisiÃ³n estratificada

Cross-Validation - ValidaciÃ³n cruzada k-fold

Hyperparameter Tuning - BÃºsqueda en grid y random

Learning Curves - DetecciÃ³n de overfitting/underfitting

PrevenciÃ³n de Overfitting
RegularizaciÃ³n (L1/L2)

Early stopping

ValidaciÃ³n cruzada

Pruning (Ã¡rboles)

ğŸ“ˆ Resultados Destacados
Proyecto Principal - PredicciÃ³n de Precios
RÂ²: 0.85+ en conjunto de test

RMSE: Menos del 15% del precio promedio

CaracterÃ­sticas mÃ¡s importantes: Metros cuadrados, ubicaciÃ³n, antigÃ¼edad

ğŸ¤ ContribuciÃ³n
Estructura de CÃ³digo
Seguir principios SOLID

Documentar con docstrings

Mantener coherencia en naming

Incluir tests unitarios

Flujo de Trabajo
Fork del proyecto

Crear rama feature (git checkout -b feature/AmazingFeature)

Commit cambios (git commit -m 'Add AmazingFeature')

Push a la rama (git push origin feature/AmazingFeature)

Abrir Pull Request