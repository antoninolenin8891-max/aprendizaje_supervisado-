# üéì Dashboard Interactivo - Aprendizaje Supervisado

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**Dashboard interactivo que integra algoritmos de Machine Learning supervisado con una arquitectura POO modular**

[Demo en Vivo](#) ‚Ä¢ [Documentaci√≥n](#) ‚Ä¢ [Reportar Bug](../../issues) ‚Ä¢ [Solicitar Feature](../../issues)

</div>

---

## üìã Descripci√≥n

Dashboard educativo e interactivo desarrollado en Python que implementa una suite completa de algoritmos de aprendizaje supervisado. El proyecto combina teor√≠a y pr√°ctica de Machine Learning con principios de Programaci√≥n Orientada a Objetos, ofreciendo una interfaz amigable construida con Streamlit.

### üéØ Objetivo Principal

Desarrollar un sistema completo de predicci√≥n de precios de propiedades utilizando el dataset de King County, implementando un pipeline de ML desde la exploraci√≥n de datos hasta el deployment de modelos.

---

## ‚ú® Caracter√≠sticas Principales

### ü§ñ Algoritmos Implementados

| Algoritmo | Tipo | Uso Principal | Complejidad |
|-----------|------|---------------|-------------|
| **Regresi√≥n Lineal** | Regresi√≥n | Predicci√≥n de valores continuos | ‚≠ê B√°sico |
| **Ridge & Lasso** | Regresi√≥n | Regularizaci√≥n L1/L2 | ‚≠ê‚≠ê Intermedio |
| **Regresi√≥n Log√≠stica** | Clasificaci√≥n | Problemas binarios/multiclase | ‚≠ê‚≠ê Intermedio |
| **K-Nearest Neighbors** | Ambos | Clasificaci√≥n basada en similitud | ‚≠ê‚≠ê Intermedio |
| **√Årboles de Decisi√≥n** | Ambos | Modelos interpretables | ‚≠ê‚≠ê Intermedio |
| **Redes Neuronales** | Ambos | Problemas no lineales complejos | ‚≠ê‚≠ê‚≠ê Avanzado |

### üè° Proyecto Integrador: Predicci√≥n de Precios Inmobiliarios

- **Dataset**: King County House Sales (21,000+ propiedades)
- **Variables**: 21 caracter√≠sticas (√°rea, ubicaci√≥n, a√±o construcci√≥n, etc.)
- **Target**: Precio de venta en USD
- **Pipeline completo**: EDA ‚Üí Preprocesamiento ‚Üí Feature Engineering ‚Üí Modelado ‚Üí Evaluaci√≥n ‚Üí Deployment

---

## üõ†Ô∏è Stack Tecnol√≥gico

<table>
<tr>
<td>

**Backend & ML**
- Python 3.8+
- scikit-learn 1.3+
- pandas 2.0+
- numpy 1.24+
- matplotlib/seaborn

</td>
<td>

**Frontend**
- Streamlit 1.28+
- Plotly 5.17+
- Altair 5.1+

</td>
<td>

**Arquitectura**
- POO (SOLID)
- MVC Pattern
- Modular Pipeline
- Type Hints

</td>
</tr>
</table>

---

## üìÅ Estructura del Proyecto

```
ml-dashboard/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ main_dashboard.py          # Aplicaci√≥n principal Streamlit
‚îú‚îÄ‚îÄ üìÑ requirements.txt           # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ README.md                  # Documentaci√≥n principal
‚îú‚îÄ‚îÄ üìÑ .gitignore                 # Archivos ignorados por Git
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ king_county.csv           # Dataset principal
‚îÇ   ‚îî‚îÄ‚îÄ README.md                 # Descripci√≥n del dataset
‚îÇ
‚îú‚îÄ‚îÄ üìÇ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py            # Carga de datos
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessor.py      # Limpieza y transformaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineer.py       # Ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py          # Entrenamiento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluator.py        # Evaluaci√≥n y m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ predictor.py              # Sistema de predicci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ   ‚îî‚îÄ‚îÄ saved_models/             # Modelos entrenados (.pkl)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_model_comparison.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üìÇ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_data_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessor.py
‚îÇ   ‚îî‚îÄ‚îÄ test_models.py
‚îÇ
‚îî‚îÄ‚îÄ üìÇ docs/
    ‚îú‚îÄ‚îÄ architecture.md           # Diagrama de arquitectura
    ‚îú‚îÄ‚îÄ algorithms.md             # Gu√≠a de algoritmos
    ‚îî‚îÄ‚îÄ api_reference.md          # Referencia de API
```

---

## üèóÔ∏è Arquitectura POO

### Diagrama de Clases

```mermaid
classDiagram
    class DataLoader {
        +load_data()
        +split_data()
        +get_info()
    }
    
    class DataPreprocessor {
        +handle_missing()
        +encode_categorical()
        +scale_features()
    }
    
    class FeatureEngineer {
        +create_features()
        +select_features()
        +reduce_dimensions()
    }
    
    class ModelTrainer {
        +train()
        +cross_validate()
        +tune_hyperparameters()
    }
    
    class ModelEvaluator {
        +evaluate()
        +plot_metrics()
        +generate_report()
    }
    
    class Predictor {
        +predict()
        +predict_proba()
        +explain_prediction()
    }
    
    DataLoader --> DataPreprocessor
    DataPreprocessor --> FeatureEngineer
    FeatureEngineer --> ModelTrainer
    ModelTrainer --> ModelEvaluator
    ModelEvaluator --> Predictor
```

### Responsabilidades de Clases

#### üîµ `DataLoader`
**Prop√≥sito**: Gesti√≥n de carga y partici√≥n de datos

```python
- load_data(filepath: str) -> pd.DataFrame
- split_data(test_size: float, random_state: int) -> tuple
- get_dataset_info() -> dict
```

#### üü¢ `DataPreprocessor`
**Prop√≥sito**: Limpieza y transformaci√≥n de datos

```python
- handle_missing_values(strategy: str) -> pd.DataFrame
- encode_categorical(method: str) -> pd.DataFrame
- scale_features(scaler_type: str) -> np.ndarray
- remove_outliers(method: str) -> pd.DataFrame
```

#### üü° `FeatureEngineer`
**Prop√≥sito**: Creaci√≥n y selecci√≥n de caracter√≠sticas

```python
- create_polynomial_features(degree: int) -> pd.DataFrame
- create_interaction_features() -> pd.DataFrame
- select_features(method: str, k: int) -> list
- reduce_dimensions(method: str) -> np.ndarray
```

#### üî¥ `ModelTrainer`
**Prop√≥sito**: Entrenamiento y optimizaci√≥n de modelos

```python
- train(algorithm: str, params: dict) -> object
- cross_validate(cv: int) -> dict
- hyperparameter_tuning(param_grid: dict) -> dict
- save_model(filepath: str) -> None
```

#### üü£ `ModelEvaluator`
**Prop√≥sito**: Evaluaci√≥n exhaustiva de modelos

```python
- evaluate(y_true, y_pred) -> dict
- plot_confusion_matrix() -> None
- plot_learning_curves() -> None
- generate_classification_report() -> str
```

#### üü† `Predictor`
**Prop√≥sito**: Realizar predicciones en producci√≥n

```python
- predict(X_new: pd.DataFrame) -> np.ndarray
- predict_proba(X_new: pd.DataFrame) -> np.ndarray
- explain_prediction(instance: pd.Series) -> dict
```

---

## üìä M√©tricas de Evaluaci√≥n

### Para Problemas de Regresi√≥n

| M√©trica | F√≥rmula | Interpretaci√≥n | Mejor Valor |
|---------|---------|----------------|-------------|
| **MSE** | `Œ£(y - ≈∑)¬≤ / n` | Error cuadr√°tico promedio | 0 |
| **RMSE** | `‚àöMSE` | Error en unidades originales | 0 |
| **MAE** | `Œ£\|y - ≈∑\| / n` | Error absoluto promedio | 0 |
| **R¬≤** | `1 - (SS_res / SS_tot)` | Varianza explicada | 1 |
| **MAPE** | `Œ£\|y - ≈∑\|/y / n √ó 100` | Error porcentual | 0% |

### Para Problemas de Clasificaci√≥n

| M√©trica | F√≥rmula | Interpretaci√≥n | Mejor Valor |
|---------|---------|----------------|-------------|
| **Accuracy** | `(TP + TN) / Total` | Predicciones correctas | 1.0 |
| **Precision** | `TP / (TP + FP)` | Positivos correctos | 1.0 |
| **Recall** | `TP / (TP + FN)` | Cobertura de positivos | 1.0 |
| **F1-Score** | `2 √ó (P √ó R) / (P + R)` | Media arm√≥nica P y R | 1.0 |
| **ROC-AUC** | √Årea bajo curva ROC | Capacidad discriminante | 1.0 |

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes)
- Git
- 4GB RAM m√≠nimo
- 500MB espacio en disco

### Instalaci√≥n Paso a Paso

#### 1Ô∏è‚É£ Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/ml-dashboard.git
cd ml-dashboard
```

#### 2Ô∏è‚É£ Crear Entorno Virtual

```bash
# Linux/MacOS
python3 -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

#### 3Ô∏è‚É£ Instalar Dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 4Ô∏è‚É£ Verificar Instalaci√≥n

```bash
python -c "import streamlit; import sklearn; print('‚úÖ Todo listo!')"
```

#### 5Ô∏è‚É£ Ejecutar Dashboard

```bash
streamlit run main_dashboard.py
```

#### 6Ô∏è‚É£ Acceder a la Aplicaci√≥n

Abrir navegador en: **http://localhost:8501**

---

## üíª Uso del Dashboard

### Flujo de Trabajo

1. **üìÅ Carga de Datos**: Subir dataset o usar King County
2. **üîç An√°lisis Exploratorio**: Visualizar distribuciones y correlaciones
3. **üßπ Preprocesamiento**: Limpiar, transformar y escalar datos
4. **‚öôÔ∏è Feature Engineering**: Crear nuevas caracter√≠sticas
5. **ü§ñ Selecci√≥n de Modelo**: Elegir algoritmo y configurar hiperpar√°metros
6. **üìä Evaluaci√≥n**: Analizar m√©tricas y visualizaciones
7. **üîÆ Predicci√≥n**: Realizar predicciones sobre nuevos datos

### Ejemplo de C√≥digo

```python
from scripts.data_loader import DataLoader
from scripts.model_trainer import ModelTrainer

# Cargar datos
loader = DataLoader()
X_train, X_test, y_train, y_test = loader.load_and_split('data/king_county.csv')

# Entrenar modelo
trainer = ModelTrainer()
model = trainer.train('ridge', {'alpha': 1.0})

# Evaluar
metrics = trainer.evaluate(X_test, y_test)
print(f"R¬≤ Score: {metrics['r2']:.3f}")
```

---

## üéØ Gu√≠a de Algoritmos

### üìà Regresi√≥n Lineal

**Cu√°ndo usar**: Relaciones lineales entre variables, interpretabilidad cr√≠tica

**Ventajas**: Simple, r√°pido, interpretable, bajo riesgo de overfitting

**Limitaciones**: Asume linealidad, sensible a outliers

**Aplicaciones**: Predicci√≥n de ventas, precios, demanda

### üéØ Regresi√≥n Log√≠stica

**Cu√°ndo usar**: Clasificaci√≥n binaria, necesitas probabilidades de clase

**Ventajas**: Salida probabil√≠stica, interpretable, eficiente

**Limitaciones**: L√≠mite de decisi√≥n lineal

**Aplicaciones**: Detecci√≥n de spam, diagn√≥stico m√©dico, credit scoring

### üë• K-Nearest Neighbors

**Cu√°ndo usar**: Pocas features, patrones locales, no requiere entrenamiento

**Ventajas**: No param√©trico, simple, adaptativo

**Limitaciones**: Lento en predicci√≥n, sensible a escala y dimensionalidad

**Aplicaciones**: Sistemas de recomendaci√≥n, reconocimiento de patrones

### üå≥ √Årboles de Decisi√≥n

**Cu√°ndo usar**: Interpretabilidad crucial, datos con tipos mixtos

**Ventajas**: Muy interpretable, no requiere normalizaci√≥n, captura no linealidad

**Limitaciones**: Propenso a overfitting, inestable

**Aplicaciones**: An√°lisis de riesgo crediticio, diagn√≥stico m√©dico

### üß† Redes Neuronales

**Cu√°ndo usar**: Patrones complejos no lineales, grandes vol√∫menes de datos

**Ventajas**: Alta capacidad de modelado, feature extraction autom√°tico

**Limitaciones**: Caja negra, requiere muchos datos, computacionalmente costoso

**Aplicaciones**: Computer vision, NLP, series temporales complejas

---

## üîç Validaci√≥n y Prevenci√≥n de Overfitting

### T√©cnicas Implementadas

- ‚úÖ **Train/Validation/Test Split** (70/15/15)
- ‚úÖ **K-Fold Cross-Validation** (k=5, 10)
- ‚úÖ **Stratified K-Fold** para clases desbalanceadas
- ‚úÖ **Grid Search & Random Search** para hiperpar√°metros
- ‚úÖ **Learning Curves** para diagn√≥stico

### Estrategias Anti-Overfitting

| T√©cnica | Aplicable a | C√≥mo Funciona |
|---------|-------------|---------------|
| **Regularizaci√≥n L1/L2** | Regresi√≥n, Log√≠stica | Penaliza coeficientes grandes |
| **Early Stopping** | Redes Neuronales | Detiene entrenamiento √≥ptimo |
| **Pruning** | √Årboles | Poda ramas menos relevantes |
| **Dropout** | Redes Neuronales | Desactiva neuronas aleatoriamente |
| **Ensemble Methods** | Todos | Combina m√∫ltiples modelos |

---

## üìà Resultados del Proyecto Principal

### Predicci√≥n de Precios Inmobiliarios

| Modelo | R¬≤ Score | RMSE | MAE | Tiempo |
|--------|----------|------|-----|--------|
| **Regresi√≥n Lineal** | 0.698 | $181,452 | $117,832 | 0.05s |
| **Ridge (Œ±=1.0)** | 0.698 | $181,423 | $117,795 | 0.06s |
| **Lasso (Œ±=100)** | 0.697 | $181,632 | $117,921 | 0.08s |
| **√Årbol de Decisi√≥n** | 0.732 | $170,893 | $98,442 | 0.15s |
| **Red Neuronal** | **0.856** | **$125,234** | **$82,103** | 2.34s |

### Variables M√°s Importantes

1. üè† **sqft_living** (28.3%) - Metros cuadrados habitables
2. üìç **grade** (18.7%) - Calificaci√≥n de construcci√≥n
3. üìÖ **yr_built** (12.4%) - A√±o de construcci√≥n
4. üõèÔ∏è **bedrooms** (9.8%) - N√∫mero de habitaciones
5. üåä **waterfront** (8.2%) - Vista al agua

---

## ü§ù Contribuci√≥n

### Pautas de Desarrollo

- ‚úÖ Seguir principios **SOLID**
- ‚úÖ Documentar con **docstrings** (Google style)
- ‚úÖ Type hints en todas las funciones
- ‚úÖ Tests unitarios con cobertura >80%
- ‚úÖ Convenci√≥n de nombres: `snake_case` para funciones/variables

### Flujo de Trabajo Git

```bash
# 1. Fork del proyecto
git clone https://github.com/tu-usuario/ml-dashboard.git

# 2. Crear rama feature
git checkout -b feature/nueva-funcionalidad

# 3. Realizar cambios y commits
git add .
git commit -m "feat: agregar algoritmo Random Forest"

# 4. Push a tu fork
git push origin feature/nueva-funcionalidad

# 5. Crear Pull Request en GitHub
```

### Convenci√≥n de Commits

- `feat:` Nueva funcionalidad
- `fix:` Correcci√≥n de bug
- `docs:` Documentaci√≥n
- `style:` Formato de c√≥digo
- `refactor:` Refactorizaci√≥n
- `test:` Agregar tests

---

## üìö Recursos Adicionales

### Documentaci√≥n
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

### Tutoriales
- [Machine Learning Crash Course - Google](https://developers.google.com/machine-learning/crash-course)
- [Kaggle Learn](https://www.kaggle.com/learn)
